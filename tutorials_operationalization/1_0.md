# Deploy an AZTK Spark cluster
This guide is for Pyspark developers and will show you how to install & setup AZTK cluster in Azure.

### 1. Install and setup AZTK on your local machine:
```sh
# download and install aztk
pip install aztk

# initialize your aztk project
aztk spark init --python
```
The `aztk spark init --python` command will generate a `.aztk` folder in your current directory. Please make sure that you are able to access this folder. The `--python` flag will tell AZTK to initialize your cluster specifically with python tooling (like Jupyter).

### 2. Set up your credentials (you'll need to have an Azure account).

Login to [Azure Cloud Shell](https://shell.azure.com/).

Before you start this section, you need to know the following:
- What you want to call your AZTK project?
- What location/region do you want to deploy your project to? (run `az account list-locations -o table` in Cloud Shell to see available regions)
- A password for your AZTK project

Run the command below, replacing `<aztk-project-name>`, `<location>`, and `<password>` with your desired input.
```sh
wget https://raw.githubusercontent.com/Azure/ai-on-iaas-pp/master/tutorials_operationalization/1_0_1.sh && chmod -x 1_0_1.sh && ./1_0_1.sh -n <aztk-project-name> -l <location> -p <password>
```

The output will look like this:
```sh
# output
-----------------------------------------------------------
tenant_id: <AAD Diretory ID>
client_id: <AAD App Application ID>
credential: <AAD App Password>
batch_account_resource_id: </batch/account/resource/id>
storage_account_resource_id: </storage/account/resource/id>
-----------------------------------------------------------
```
After this command executes, copy and paste the output back from Cloud Shell to your `.aztk/secrets.yaml` file on your local machine under `service_principal:`.

### 3. Deploy your Spark cluster

You're now ready to deploy your cluster:
```sh
# this creates a 4 node spark cluster of vm-size standard_a2
aztk spark cluster create --id mysparkcluster --vm-size standard_a2 --size 4 --wait
```
This will take about 5 minutes to deploy. Take a break and come back!

### 4. Use Jupyter Notebooks and the Spark Master UI

When your cluster is ready, you can access your cluster directly from your browser.

```sh
aztk spark cluster ssh --id mysparkcluster --user spark
```

Go to your browser and open up http://localhost:8080 and http://localhost:8888 to open up your Spark Master UI and Jupyter Notebook respectively.

### Next Steps
[Learn about submitting Spark jobs remotely](...)
